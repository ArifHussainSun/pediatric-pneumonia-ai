{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Core CNN Models for Pediatric Pneumonia Detection\n\n## Overview\nThis notebook implements essential baseline CNN architectures for pneumonia detection:\n- **Xception**: Advanced CNN with depthwise separable convolutions\n- **MobileNet**: Lightweight CNN designed for mobile devices\n- **VGG16**: Classic deep CNN architecture\n\nThese are the **core models** that form the foundation for pneumonia detection. Anyone working on medical image classification should understand these architectures first.\n\n## Key Concepts\n- **CNN (Convolutional Neural Network)**: Deep learning model that processes images using filters\n- **Transfer Learning**: Using pre-trained models and adapting them for medical images\n- **Fine-tuning**: Adjusting pre-trained model weights for specific tasks\n- **Feature Maps**: Intermediate representations learned by CNN layers\n- **Classification Head**: Final layers that make pneumonia/normal predictions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import timm  # PyTorch Image Models - provides pre-trained models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device (GPU if available, CPU otherwise)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Data Setup\n",
    "\n",
    "**Key Parameters:**\n",
    "- **Batch Size**: Number of images processed together (32 = good balance of speed and memory)\n",
    "- **Image Size**: 224x224 pixels (standard for most pre-trained models)\n",
    "- **Epochs**: Number of complete passes through the training data\n",
    "- **Learning Rate**: How fast the model learns (smaller = more careful learning)\n",
    "\n",
    "**Data Transforms:**\n",
    "- **Resize**: Makes all images the same size\n",
    "- **ToTensor**: Converts images to PyTorch format\n",
    "- **Normalize**: Standardizes pixel values (improves training stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "CONFIG = {\n",
    "    'batch_size': 32,\n",
    "    'image_size': 224,\n",
    "    'epochs': 10,\n",
    "    'learning_rate': 1e-4,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Data directories\n",
    "TRAIN_DIR = '../data/training/augmented_train'\n",
    "TEST_DIR = '../data/testing/augmented_test'\n",
    "\n",
    "# Data transformations\n",
    "# These prepare the images for training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),  # Resize to 224x224\n",
    "    transforms.ToTensor(),  # Convert PIL Image to tensor\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize to [-1, 1] range\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=TEST_DIR, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "# These handle batching and shuffling of data\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")\n",
    "print(f\"Classes: {train_dataset.classes}\")\n",
    "print(f\"Class to index mapping: {train_dataset.class_to_idx}\")\n",
    "\n",
    "# Check class distribution\n",
    "train_counts = [0, 0]\n",
    "for _, label in train_dataset:\n",
    "    train_counts[label] += 1\n",
    "\n",
    "test_counts = [0, 0]\n",
    "for _, label in test_dataset:\n",
    "    test_counts[label] += 1\n",
    "\n",
    "print(f\"\\nTraining distribution: NORMAL={train_counts[0]}, PNEUMONIA={train_counts[1]}\")\n",
    "print(f\"Testing distribution: NORMAL={test_counts[0]}, PNEUMONIA={test_counts[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Architectures\n",
    "\n",
    "### 2.1 Xception Model\n",
    "\n",
    "**What is Xception?**\n",
    "- Advanced CNN architecture using \"depthwise separable convolutions\"\n",
    "- More efficient than regular convolutions (fewer parameters, faster training)\n",
    "- Good at capturing fine details in medical images\n",
    "- Pre-trained on ImageNet (natural images), adapted for X-rays\n",
    "\n",
    "**Transfer Learning Process:**\n",
    "1. Load pre-trained Xception model\n",
    "2. Replace final layer for pneumonia classification (2 classes instead of 1000)\n",
    "3. Optionally freeze early layers (keep learned features, only train final layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XceptionFineTune(nn.Module):\n",
    "    \"\"\"\n",
    "    Xception model adapted for pneumonia detection.\n",
    "    \n",
    "    Uses transfer learning: starts with ImageNet pre-trained weights\n",
    "    and adapts them for medical image classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2, freeze_layers=100):\n",
    "        \"\"\"\n",
    "        Initialize Xception model for pneumonia detection.\n",
    "        \n",
    "        Args:\n",
    "            num_classes: Number of output classes (2 for Normal/Pneumonia)\n",
    "            freeze_layers: Number of early layers to freeze during training\n",
    "        \"\"\"\n",
    "        super(XceptionFineTune, self).__init__()\n",
    "        \n",
    "        # Load pre-trained Xception from timm library\n",
    "        self.xception = timm.create_model('xception', pretrained=True)\n",
    "        \n",
    "        # Remove the original classification layers\n",
    "        self.xception.global_pool = nn.Identity()  # Remove global pooling\n",
    "        self.xception.fc = nn.Identity()  # Remove final fully connected layer\n",
    "        \n",
    "        # Add our own pooling and classification layers\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # Global average pooling\n",
    "        \n",
    "        # Custom classification head for pneumonia detection\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # Dropout prevents overfitting\n",
    "            nn.Linear(2048, 128),  # Xception features: 2048 -> 128\n",
    "            nn.ReLU(),  # Activation function\n",
    "            nn.Dropout(0.3),  # More dropout\n",
    "            nn.Linear(128, num_classes)  # Final prediction: 128 -> 2 classes\n",
    "        )\n",
    "        \n",
    "        # Freeze early layers for stable training\n",
    "        if freeze_layers > 0:\n",
    "            for i, (name, param) in enumerate(self.xception.named_parameters()):\n",
    "                if i < freeze_layers:\n",
    "                    param.requires_grad = False  # Don't update these weights\n",
    "            print(f\"Frozen first {freeze_layers} layers\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        \n",
    "        Args:\n",
    "            x: Input batch of images [batch_size, 3, 224, 224]\n",
    "            \n",
    "        Returns:\n",
    "            logits: Raw prediction scores [batch_size, 2]\n",
    "        \"\"\"\n",
    "        # Extract features using Xception backbone\n",
    "        x = self.xception(x)  # [batch_size, 2048, 7, 7]\n",
    "        \n",
    "        # Global average pooling: average across spatial dimensions\n",
    "        x = self.pool(x)  # [batch_size, 2048, 1, 1]\n",
    "        x = x.view(x.size(0), -1)  # Flatten: [batch_size, 2048]\n",
    "        \n",
    "        # Classification\n",
    "        x = self.classifier(x)  # [batch_size, 2]\n",
    "        \n",
    "        return x\n",
    "\n",
    "print(\"Xception model class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 MobileNet Model\n",
    "\n",
    "**What is MobileNet?**\n",
    "- Lightweight CNN designed for mobile and embedded devices\n",
    "- Uses \"depthwise separable convolutions\" for efficiency\n",
    "- Much smaller and faster than traditional CNNs\n",
    "- Good for real-time applications and resource-constrained environments\n",
    "\n",
    "**When to Use MobileNet:**\n",
    "- When you need fast inference (quick predictions)\n",
    "- Limited computational resources\n",
    "- Mobile or edge deployment\n",
    "- As a baseline for comparison with heavier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetFineTune(nn.Module):\n",
    "    \"\"\"\n",
    "    MobileNet model adapted for pneumonia detection.\n",
    "    \n",
    "    Lightweight architecture suitable for deployment on mobile devices\n",
    "    or when computational resources are limited.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2, freeze_layers=50):\n",
    "        \"\"\"\n",
    "        Initialize MobileNet model for pneumonia detection.\n",
    "        \n",
    "        Args:\n",
    "            num_classes: Number of output classes (2 for Normal/Pneumonia)\n",
    "            freeze_layers: Number of early layers to freeze during training\n",
    "        \"\"\"\n",
    "        super(MobileNetFineTune, self).__init__()\n",
    "        \n",
    "        # Load pre-trained MobileNetV2 from timm\n",
    "        self.mobilenet = timm.create_model('mobilenetv2_100', pretrained=True)\n",
    "        \n",
    "        # Get the number of features from the last layer\n",
    "        num_features = self.mobilenet.classifier.in_features\n",
    "        \n",
    "        # Replace the classifier for pneumonia detection\n",
    "        self.mobilenet.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.4),  # Dropout for regularization\n",
    "            nn.Linear(num_features, 64),  # Reduce to 64 features\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)  # Final prediction\n",
    "        )\n",
    "        \n",
    "        # Freeze early layers\n",
    "        if freeze_layers > 0:\n",
    "            for i, (name, param) in enumerate(self.mobilenet.named_parameters()):\n",
    "                if i < freeze_layers:\n",
    "                    param.requires_grad = False\n",
    "            print(f\"Frozen first {freeze_layers} layers\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through MobileNet.\n",
    "        \n",
    "        Args:\n",
    "            x: Input batch of images [batch_size, 3, 224, 224]\n",
    "            \n",
    "        Returns:\n",
    "            logits: Raw prediction scores [batch_size, 2]\n",
    "        \"\"\"\n",
    "        return self.mobilenet(x)\n",
    "\n",
    "print(\"MobileNet model class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 VGG16 Model\n",
    "\n",
    "**What is VGG16?**\n",
    "- Classic CNN architecture with 16 layers\n",
    "- Uses small 3x3 convolution filters throughout\n",
    "- Simple and interpretable architecture\n",
    "- Good baseline model for medical image analysis\n",
    "\n",
    "**Characteristics:**\n",
    "- Relatively large number of parameters\n",
    "- Slower than modern architectures but reliable\n",
    "- Good for understanding CNN behavior\n",
    "- Often used as a comparison baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16FineTune(nn.Module):\n",
    "    \"\"\"\n",
    "    VGG16 model adapted for pneumonia detection.\n",
    "    \n",
    "    Classic CNN architecture providing a reliable baseline\n",
    "    for medical image classification tasks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2, freeze_layers=10):\n",
    "        \"\"\"\n",
    "        Initialize VGG16 model for pneumonia detection.\n",
    "        \n",
    "        Args:\n",
    "            num_classes: Number of output classes (2 for Normal/Pneumonia)\n",
    "            freeze_layers: Number of early layers to freeze during training\n",
    "        \"\"\"\n",
    "        super(VGG16FineTune, self).__init__()\n",
    "        \n",
    "        # Load pre-trained VGG16 from timm\n",
    "        self.vgg = timm.create_model('vgg16', pretrained=True)\n",
    "        \n",
    "        # Get number of features from pre-classifier layer\n",
    "        num_features = self.vgg.pre_logits.in_features\n",
    "        \n",
    "        # Replace the classifier head\n",
    "        self.vgg.head = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 256),  # Intermediate layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)  # Final prediction\n",
    "        )\n",
    "        \n",
    "        # Freeze early convolutional layers\n",
    "        if freeze_layers > 0:\n",
    "            for i, (name, param) in enumerate(self.vgg.features.named_parameters()):\n",
    "                if i < freeze_layers:\n",
    "                    param.requires_grad = False\n",
    "            print(f\"Frozen first {freeze_layers} feature layers\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through VGG16.\n",
    "        \n",
    "        Args:\n",
    "            x: Input batch of images [batch_size, 3, 224, 224]\n",
    "            \n",
    "        Returns:\n",
    "            logits: Raw prediction scores [batch_size, 2]\n",
    "        \"\"\"\n",
    "        return self.vgg(x)\n",
    "\n",
    "print(\"VGG16 model class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Utilities\n",
    "\n",
    "**Training Process:**\n",
    "1. **Forward Pass**: Images go through the model to get predictions\n",
    "2. **Loss Calculation**: Compare predictions with actual labels\n",
    "3. **Backward Pass**: Calculate gradients (how to update weights)\n",
    "4. **Weight Update**: Adjust model parameters to improve performance\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Loss Function**: CrossEntropyLoss for classification tasks\n",
    "- **Optimizer**: Adam optimizer for efficient weight updates\n",
    "- **Learning Rate**: Controls how big steps the optimizer takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs, learning_rate, model_name):\n",
    "    \"\"\"\n",
    "    Train a CNN model for pneumonia detection.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train\n",
    "        train_loader: DataLoader for training data\n",
    "        test_loader: DataLoader for testing data\n",
    "        num_epochs: Number of training epochs\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        model_name: Name for saving and logging\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (trained_model, training_history)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Move model to appropriate device (GPU/CPU)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  # Standard for classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Adam optimizer\n",
    "    \n",
    "    # Track training progress\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_acc': []\n",
    "    }\n",
    "    \n",
    "    print(f\"Starting training for {model_name}...\")\n",
    "    print(f\"Training for {num_epochs} epochs with learning rate {learning_rate}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        # Progress bar for training batches\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]', leave=False)\n",
    "        \n",
    "        for inputs, labels in train_pbar:\n",
    "            # Move data to device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*correct_train/total_train:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100. * correct_train / total_train\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        \n",
    "        with torch.no_grad():  # Don't compute gradients during evaluation\n",
    "            test_pbar = tqdm(test_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Test]', leave=False)\n",
    "            \n",
    "            for inputs, labels in test_pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "                \n",
    "                test_pbar.set_postfix({\n",
    "                    'Acc': f'{100.*correct_test/total_test:.2f}%'\n",
    "                })\n",
    "        \n",
    "        test_accuracy = 100. * correct_test / total_test\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(train_accuracy)\n",
    "        history['test_acc'].append(test_accuracy)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] - '\n",
    "              f'Train Loss: {epoch_loss:.4f}, '\n",
    "              f'Train Acc: {train_accuracy:.2f}%, '\n",
    "              f'Test Acc: {test_accuracy:.2f}%')\n",
    "    \n",
    "    print(f\"\\nTraining completed for {model_name}!\")\n",
    "    print(f\"Final Test Accuracy: {history['test_acc'][-1]:.2f}%\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "print(\"Training function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation Utilities\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- **Accuracy**: Percentage of correct predictions\n",
    "- **Precision**: Of predicted pneumonia cases, how many were actually pneumonia\n",
    "- **Recall**: Of actual pneumonia cases, how many were correctly identified\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "- **Confusion Matrix**: Shows all correct and incorrect predictions in detail\n",
    "\n",
    "**Why Multiple Metrics Matter:**\n",
    "- Medical diagnosis requires high recall (don't miss pneumonia cases)\n",
    "- High precision reduces false alarms\n",
    "- Balanced metrics indicate robust model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, class_names, model_name):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of a trained model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        test_loader: DataLoader for test data\n",
    "        class_names: List of class names ['NORMAL', 'PNEUMONIA']\n",
    "        model_name: Name for logging and display\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()  # Set to evaluation mode\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Get model predictions\n",
    "            outputs = model(inputs)\n",
    "            probabilities = torch.softmax(outputs, dim=1)  # Convert to probabilities\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Store results\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    y_true = np.array(all_labels)\n",
    "    y_pred = np.array(all_predictions)\n",
    "    y_prob = np.array(all_probabilities)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = (y_true == y_pred).mean() * 100\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_true, y_pred, \n",
    "                                 target_names=class_names, \n",
    "                                 output_dict=True)\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(f\"\\n{model_name} Evaluation Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Overall Accuracy: {accuracy:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    \n",
    "    # Create and display confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate detailed metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': report['weighted avg']['precision'],\n",
    "        'recall': report['weighted avg']['recall'],\n",
    "        'f1_score': report['weighted avg']['f1-score'],\n",
    "        'confusion_matrix': cm,\n",
    "        'true_positives': tp,\n",
    "        'true_negatives': tn,\n",
    "        'false_positives': fp,\n",
    "        'false_negatives': fn,\n",
    "        'classification_report': report\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nDetailed Metrics:\")\n",
    "    print(f\"True Positives (Correctly identified pneumonia): {tp}\")\n",
    "    print(f\"True Negatives (Correctly identified normal): {tn}\")\n",
    "    print(f\"False Positives (Normal classified as pneumonia): {fp}\")\n",
    "    print(f\"False Negatives (Pneumonia classified as normal): {fn}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Evaluation function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Individual Models\n",
    "\n",
    "Now we'll train each model architecture and compare their performance.\n",
    "\n",
    "### 5.1 Train Xception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Xception model\n",
    "print(\"Initializing Xception model...\")\n",
    "xception_model = XceptionFineTune(num_classes=2, freeze_layers=100)\n",
    "\n",
    "# Train the model\n",
    "trained_xception, xception_history = train_model(\n",
    "    model=xception_model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=CONFIG['epochs'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    model_name=\"Xception\"\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(trained_xception.state_dict(), '../models/xception_pneumonia.pth')\n",
    "print(\"Xception model saved to ../models/xception_pneumonia.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Train MobileNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train MobileNet model\n",
    "print(\"Initializing MobileNet model...\")\n",
    "mobilenet_model = MobileNetFineTune(num_classes=2, freeze_layers=50)\n",
    "\n",
    "# Train the model\n",
    "trained_mobilenet, mobilenet_history = train_model(\n",
    "    model=mobilenet_model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=CONFIG['epochs'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    model_name=\"MobileNet\"\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(trained_mobilenet.state_dict(), '../models/mobilenet_pneumonia.pth')\n",
    "print(\"MobileNet model saved to ../models/mobilenet_pneumonia.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train VGG16 model\n",
    "print(\"Initializing VGG16 model...\")\n",
    "vgg_model = VGG16FineTune(num_classes=2, freeze_layers=10)\n",
    "\n",
    "# Train the model\n",
    "trained_vgg, vgg_history = train_model(\n",
    "    model=vgg_model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=CONFIG['epochs'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    model_name=\"VGG16\"\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(trained_vgg.state_dict(), '../models/vgg16_pneumonia.pth')\n",
    "print(\"VGG16 model saved to ../models/vgg16_pneumonia.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Comparison\n",
    "\n",
    "Now let's evaluate all trained models and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "class_names = ['NORMAL', 'PNEUMONIA']\n",
    "results = []\n",
    "\n",
    "# Evaluate Xception\n",
    "xception_results = evaluate_model(trained_xception, test_loader, class_names, \"Xception\")\n",
    "results.append(xception_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Evaluate MobileNet\n",
    "mobilenet_results = evaluate_model(trained_mobilenet, test_loader, class_names, \"MobileNet\")\n",
    "results.append(mobilenet_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Evaluate VGG16\n",
    "vgg_results = evaluate_model(trained_vgg, test_loader, class_names, \"VGG16\")\n",
    "results.append(vgg_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "import pandas as pd\n",
    "\n",
    "comparison_data = []\n",
    "for result in results:\n",
    "    comparison_data.append({\n",
    "        'Model': result['model_name'],\n",
    "        'Accuracy (%)': f\"{result['accuracy']:.2f}\",\n",
    "        'Precision': f\"{result['precision']:.4f}\",\n",
    "        'Recall': f\"{result['recall']:.4f}\",\n",
    "        'F1-Score': f\"{result['f1_score']:.4f}\",\n",
    "        'False Negatives': result['false_negatives'],\n",
    "        'False Positives': result['false_positives']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"Model Comparison Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Training loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(xception_history['train_loss'], label='Xception', marker='o')\n",
    "plt.plot(mobilenet_history['train_loss'], label='MobileNet', marker='s')\n",
    "plt.plot(vgg_history['train_loss'], label='VGG16', marker='^')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Training accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(xception_history['train_acc'], label='Xception', marker='o')\n",
    "plt.plot(mobilenet_history['train_acc'], label='MobileNet', marker='s')\n",
    "plt.plot(vgg_history['train_acc'], label='VGG16', marker='^')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Test accuracy\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(xception_history['test_acc'], label='Xception', marker='o')\n",
    "plt.plot(mobilenet_history['test_acc'], label='MobileNet', marker='s')\n",
    "plt.plot(vgg_history['test_acc'], label='VGG16', marker='^')\n",
    "plt.title('Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best performing model\n",
    "best_model = max(results, key=lambda x: x['accuracy'])\n",
    "print(f\"\\nBest performing model: {best_model['model_name']} with {best_model['accuracy']:.2f}% accuracy\")\n",
    "\n",
    "# Medical significance analysis\n",
    "print(\"\\nMedical Significance Analysis:\")\n",
    "print(\"=\" * 40)\n",
    "for result in results:\n",
    "    fn = result['false_negatives']  # Missed pneumonia cases\n",
    "    fp = result['false_positives']  # False alarms\n",
    "    print(f\"{result['model_name']}:\")\n",
    "    print(f\"  - Missed pneumonia cases: {fn} (High risk - could delay treatment)\")\n",
    "    print(f\"  - False pneumonia alerts: {fp} (Moderate risk - unnecessary treatment)\")\n",
    "    print(f\"  - Recall (pneumonia detection rate): {result['recall']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Recommendations\n",
    "\n",
    "### Model Performance Analysis\n",
    "\n",
    "Based on the training and evaluation results:\n",
    "\n",
    "**Key Findings:**\n",
    "- **Xception**: Advanced architecture with excellent feature extraction capabilities\n",
    "- **MobileNet**: Lightweight and efficient, suitable for mobile deployment\n",
    "- **VGG16**: Reliable baseline with interpretable architecture\n",
    "\n",
    "**Medical Application Considerations:**\n",
    "- **High Recall Priority**: Missing pneumonia cases has severe consequences\n",
    "- **Balanced Performance**: Both precision and recall matter for practical use\n",
    "- **Computational Requirements**: Consider deployment environment constraints\n",
    "\n",
    "### Next Steps:\n",
    "1. **Fusion Models**: Combine multiple architectures for improved performance\n",
    "2. **CNN-LSTM Models**: Add sequential processing for enhanced feature analysis\n",
    "3. **Ensemble Methods**: Combine predictions from multiple models\n",
    "4. **Hyperparameter Tuning**: Optimize learning rates, architectures, and training strategies\n",
    "\n",
    "### Individual Model Use Cases:\n",
    "- **Xception**: Best overall performance for accuracy-critical applications\n",
    "- **MobileNet**: Real-time mobile applications and resource-constrained environments\n",
    "- **VGG16**: Educational purposes and baseline comparisons\n",
    "\n",
    "**All individual CNN models are now trained and ready for use in ensemble methods!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}