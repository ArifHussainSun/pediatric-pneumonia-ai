{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods for Pneumonia Detection\n",
    "\n",
    "This notebook demonstrates ensemble methods that combine multiple models to improve pneumonia detection accuracy. The approach integrates:\n",
    "\n",
    "1. **Deep Learning Models**: Xception and Xception-LSTM architectures\n",
    "2. **Traditional Machine Learning**: SVM with statistical feature extraction\n",
    "3. **Ensemble Fusion**: Weighted averaging of model predictions\n",
    "\n",
    "The ensemble approach leverages the strengths of different model types to achieve better generalization and robustness in medical image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import timm\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "IMAGE_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Architectures\n",
    "\n",
    "### 2.1 Xception-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XceptionLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Xception-LSTM hybrid model for spatial-temporal feature learning.\n",
    "    Combines Xception CNN feature extraction with LSTM sequence modeling.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_layers=100):\n",
    "        super(XceptionLSTM, self).__init__()\n",
    "        self.xception = timm.create_model(\"xception\", pretrained=True, features_only=True)\n",
    "        \n",
    "        # Freeze early layers for transfer learning\n",
    "        for i, (name, param) in enumerate(self.xception.named_parameters()):\n",
    "            if i < freeze_layers:\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.reshape = nn.Flatten(2)\n",
    "        self.transpose = lambda x: x.permute(0, 2, 1)\n",
    "        \n",
    "        # LSTM for sequence modeling of spatial features\n",
    "        self.lstm = nn.LSTM(input_size=2048, hidden_size=256, batch_first=True)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.dropout = nn.Dropout(0.46)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using Xception backbone\n",
    "        x = self.xception(x)[-1]  # Use final feature layer\n",
    "        x = self.pool(x)\n",
    "        x = self.reshape(x)\n",
    "        x = self.transpose(x)\n",
    "        \n",
    "        # Process through LSTM\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]  # Use final LSTM output\n",
    "        \n",
    "        # Classification\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Xception Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XceptionFineTune(nn.Module):\n",
    "    \"\"\"\n",
    "    Fine-tuned Xception model for pneumonia classification.\n",
    "    Uses global average pooling and custom classification head.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(XceptionFineTune, self).__init__()\n",
    "        self.xception = timm.create_model('xception', pretrained=True)\n",
    "        \n",
    "        # Remove default classification layers\n",
    "        self.xception.global_pool = nn.Identity()\n",
    "        self.xception.fc = nn.Identity()\n",
    "        \n",
    "        # Custom pooling and classification\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.xception(x)\n",
    "        x = self.pool(x).view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xception_lstm(weights_path=\"../models/xception_lstm_weights.pth\"):\n",
    "    \"\"\"Load the XceptionLSTM model with pre-trained weights\"\"\"\n",
    "    model = XceptionLSTM()\n",
    "    if os.path.exists(weights_path):\n",
    "        model.load_state_dict(torch.load(weights_path, map_location=DEVICE))\n",
    "        print(f\"Loaded XceptionLSTM weights from {weights_path}\")\n",
    "    else:\n",
    "        print(f\"Warning: XceptionLSTM weights not found at {weights_path}\")\n",
    "        print(\"Using randomly initialized weights\")\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_xception(weights_path=\"../models/xception_weights.pth\"):\n",
    "    \"\"\"Load the Xception model with pre-trained weights\"\"\"\n",
    "    model = XceptionFineTune()\n",
    "    if os.path.exists(weights_path):\n",
    "        model.load_state_dict(torch.load(weights_path, map_location=DEVICE))\n",
    "        print(f\"Loaded Xception weights from {weights_path}\")\n",
    "    else:\n",
    "        print(f\"Warning: Xception weights not found at {weights_path}\")\n",
    "        print(\"Using randomly initialized weights\")\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_svm(model_path=\"../models/svm_model.pkl\", \n",
    "             scaler_path=\"../models/feature_scaler.pkl\",\n",
    "             features_file=\"../data/test_features.csv\"):\n",
    "    \"\"\"\n",
    "    Load the SVM model, feature scaler, and pre-extracted features\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the SVM model file\n",
    "        scaler_path: Path to the feature scaler file\n",
    "        features_file: Path to the CSV file containing pre-extracted features\n",
    "    \"\"\"\n",
    "    if not all(os.path.exists(p) for p in [model_path, scaler_path]):\n",
    "        print(\"Warning: SVM model or scaler not found\")\n",
    "        return None, None, {}\n",
    "    \n",
    "    # Load model and scaler\n",
    "    svm_model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    print(f\"Loaded SVM model from {model_path}\")\n",
    "    print(f\"Loaded feature scaler from {scaler_path}\")\n",
    "    \n",
    "    # Load pre-extracted features if available\n",
    "    features_dict = {}\n",
    "    if os.path.exists(features_file):\n",
    "        print(f\"Loading features from {features_file}...\")\n",
    "        test_df = pd.read_csv(features_file, float_precision='high', low_memory=False)\n",
    "        \n",
    "        # Create feature dictionary\n",
    "        feature_columns = [col for col in test_df.columns if col not in ['image_id', 'label']]\n",
    "        \n",
    "        for _, row in test_df.iterrows():\n",
    "            image_id = os.path.splitext(os.path.basename(str(row['image_id'])))[0].lower()\n",
    "            features = row[feature_columns].values.astype(np.float32)\n",
    "            features = scaler.transform([features])[0]  # Scale the features\n",
    "            features_dict[image_id] = features\n",
    "        \n",
    "        print(f\"Loaded features for {len(features_dict)} images\")\n",
    "    else:\n",
    "        print(f\"Warning: Features file not found at {features_file}\")\n",
    "    \n",
    "    return svm_model, scaler, features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess image for CNN models\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return transform(image).unsqueeze(0).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble Prediction System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ensemble(image_path, models=None, fallback_to_cnn=True):\n",
    "    \"\"\"\n",
    "    Make prediction using ensemble of models\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        models: Dictionary containing pre-loaded models (optional)\n",
    "        fallback_to_cnn: If True, use only CNNs if SVM features are missing\n",
    "    \"\"\"\n",
    "    # Load models if not provided\n",
    "    if models is None:\n",
    "        models = {\n",
    "            'xception_lstm': load_xception_lstm(),\n",
    "            'xception': load_xception(),\n",
    "            'svm_model': None,\n",
    "            'features_dict': {}\n",
    "        }\n",
    "        models['svm_model'], _, models['features_dict'] = load_svm()\n",
    "    \n",
    "    # Preprocess image for CNN models\n",
    "    image_tensor = preprocess_image(image_path)\n",
    "    \n",
    "    # Get image ID from path\n",
    "    image_id = os.path.splitext(os.path.basename(image_path))[0].lower()\n",
    "    \n",
    "    # Get CNN predictions\n",
    "    model_predictions = {}\n",
    "    with torch.no_grad():\n",
    "        if models['xception_lstm'] is not None:\n",
    "            xc_lstm_pred = torch.sigmoid(models['xception_lstm'](image_tensor)).item()\n",
    "            model_predictions['xception_lstm'] = xc_lstm_pred\n",
    "        \n",
    "        if models['xception'] is not None:\n",
    "            xc_pred = torch.sigmoid(models['xception'](image_tensor)).item()\n",
    "            model_predictions['xception'] = xc_pred\n",
    "    \n",
    "    # Get SVM prediction if available\n",
    "    svm_pred = None\n",
    "    if (models['svm_model'] is not None and \n",
    "        image_id in models['features_dict']):\n",
    "        features = models['features_dict'][image_id].reshape(1, -1)\n",
    "        svm_pred = models['svm_model'].predict_proba(features)[0][1]  # Probability for pneumonia\n",
    "        model_predictions['svm'] = svm_pred\n",
    "    elif not fallback_to_cnn:\n",
    "        raise ValueError(f\"Pre-extracted features not found for image {image_id}\")\n",
    "    \n",
    "    # Ensemble prediction with weighted averaging\n",
    "    valid_predictions = [p for p in model_predictions.values() if p is not None]\n",
    "    \n",
    "    if len(valid_predictions) == 0:\n",
    "        raise ValueError(\"No valid predictions from any model\")\n",
    "    \n",
    "    # Equal weighting for available models\n",
    "    avg_pred = np.mean(valid_predictions)\n",
    "    final_pred = 1 if avg_pred > 0.5 else 0\n",
    "    confidence = avg_pred if final_pred == 1 else (1 - avg_pred)\n",
    "    \n",
    "    return {\n",
    "        'final_prediction': 'PNEUMONIA' if final_pred == 1 else 'NORMAL',\n",
    "        'confidence': confidence,\n",
    "        'prob_pneumonia': avg_pred,\n",
    "        'model_predictions': model_predictions,\n",
    "        'num_models': len(valid_predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(test_dir=\"../data/test\", \n",
    "                     features_file=\"../data/test_features.csv\",\n",
    "                     fallback_to_cnn=True):\n",
    "    \"\"\"\n",
    "    Evaluate the ensemble model on a test set\n",
    "    \n",
    "    Args:\n",
    "        test_dir: Directory containing test images in 'pneumonia' and 'normal' subfolders\n",
    "        features_file: Path to CSV file containing pre-extracted features\n",
    "        fallback_to_cnn: If True, use only CNNs for images with missing SVM features\n",
    "    \"\"\"\n",
    "    # Load all models once\n",
    "    print(\"Loading models...\")\n",
    "    models = {\n",
    "        'xception_lstm': load_xception_lstm(),\n",
    "        'xception': load_xception(),\n",
    "        'svm_model': None,\n",
    "        'features_dict': {}\n",
    "    }\n",
    "    models['svm_model'], _, models['features_dict'] = load_svm(features_file=features_file)\n",
    "    \n",
    "    # Collect image paths and true labels\n",
    "    image_paths = []\n",
    "    true_labels = []\n",
    "    \n",
    "    # Look for images in subdirectories\n",
    "    for class_name, label in [('normal', 0), ('pneumonia', 1)]:\n",
    "        class_dir = os.path.join(test_dir, class_name)\n",
    "        if os.path.exists(class_dir):\n",
    "            class_images = glob.glob(os.path.join(class_dir, '*.jpg')) + \\\n",
    "                          glob.glob(os.path.join(class_dir, '*.jpeg')) + \\\n",
    "                          glob.glob(os.path.join(class_dir, '*.png'))\n",
    "            image_paths.extend(class_images)\n",
    "            true_labels.extend([label] * len(class_images))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"Error: No images found in {test_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nEvaluating on {len(image_paths)} test images...\")\n",
    "    \n",
    "    # Get predictions\n",
    "    prob_pneumonia_list = []\n",
    "    model_counts = {'xception_lstm': 0, 'xception': 0, 'svm': 0}\n",
    "    \n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processing image {i+1}/{len(image_paths)}...\")\n",
    "        \n",
    "        try:\n",
    "            result = predict_ensemble(img_path, models, fallback_to_cnn)\n",
    "            prob_pneumonia_list.append(result['prob_pneumonia'])\n",
    "            \n",
    "            # Count model usage\n",
    "            for model_name in result['model_predictions']:\n",
    "                model_counts[model_name] += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            prob_pneumonia_list.append(0.5)  # Default prediction\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    true_labels = np.array(true_labels)\n",
    "    prob_pneumonia = np.array(prob_pneumonia_list)\n",
    "    pred_labels = (prob_pneumonia > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate and display results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Ensemble Model Evaluation Results\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nModel Usage Statistics:\")\n",
    "    for model_name, count in model_counts.items():\n",
    "        print(f\"- {model_name.replace('_', ' ').title()}: {count}/{len(image_paths)} images\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, pred_labels, \n",
    "                                target_names=['NORMAL', 'PNEUMONIA'],\n",
    "                                digits=4))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                  display_labels=['NORMAL', 'PNEUMONIA'])\n",
    "    disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "    plt.title('Ensemble Model - Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Detailed metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(\"\\nDetailed Metrics:\")\n",
    "    print(f\"{'Accuracy:':<15} {accuracy:.4f}\")\n",
    "    print(f\"{'Precision:':<15} {precision:.4f}\")\n",
    "    print(f\"{'Recall:':<15} {recall:.4f}\")\n",
    "    print(f\"{'F1-Score:':<15} {f1:.4f}\")\n",
    "    print(f\"{'True Positives:':<15} {tp}\")\n",
    "    print(f\"{'False Positives:':<15} {fp}\")\n",
    "    print(f\"{'True Negatives:':<15} {tn}\")\n",
    "    print(f\"{'False Negatives:':<15} {fn}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'model_counts': model_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Single Image Prediction Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_single_prediction(image_path):\n",
    "    \"\"\"\n",
    "    Demonstrate ensemble prediction on a single image\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: Image file {image_path} not found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Making prediction for: {os.path.basename(image_path)}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        result = predict_ensemble(image_path, fallback_to_cnn=True)\n",
    "        \n",
    "        print(f\"Final Prediction: {result['final_prediction']}\")\n",
    "        print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "        print(f\"Pneumonia Probability: {result['prob_pneumonia']:.4f}\")\n",
    "        print(f\"Models Used: {result['num_models']}\")\n",
    "        \n",
    "        print(\"\\nIndividual Model Predictions:\")\n",
    "        for model, pred in result['model_predictions'].items():\n",
    "            model_name = model.replace('_', ' ').title()\n",
    "            if pred is not None:\n",
    "                print(f\"- {model_name}: {pred:.4f}\")\n",
    "            else:\n",
    "                print(f\"- {model_name}: Not Available\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error making prediction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Comparison Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_individual_vs_ensemble(test_dir=\"../data/test\", sample_size=100):\n",
    "    \"\"\"\n",
    "    Compare performance of individual models vs ensemble\n",
    "    \"\"\"\n",
    "    print(\"Comparing Individual Models vs Ensemble\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load models\n",
    "    models = {\n",
    "        'xception_lstm': load_xception_lstm(),\n",
    "        'xception': load_xception(),\n",
    "        'svm_model': None,\n",
    "        'features_dict': {}\n",
    "    }\n",
    "    models['svm_model'], _, models['features_dict'] = load_svm()\n",
    "    \n",
    "    # Get test images\n",
    "    image_paths = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for class_name, label in [('normal', 0), ('pneumonia', 1)]:\n",
    "        class_dir = os.path.join(test_dir, class_name)\n",
    "        if os.path.exists(class_dir):\n",
    "            class_images = glob.glob(os.path.join(class_dir, '*.jpg'))[:sample_size//2]\n",
    "            image_paths.extend(class_images)\n",
    "            true_labels.extend([label] * len(class_images))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(\"No test images found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Testing on {len(image_paths)} images...\")\n",
    "    \n",
    "    # Collect predictions from each model\n",
    "    predictions = {\n",
    "        'xception_lstm': [],\n",
    "        'xception': [],\n",
    "        'svm': [],\n",
    "        'ensemble': []\n",
    "    }\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        image_tensor = preprocess_image(img_path)\n",
    "        image_id = os.path.splitext(os.path.basename(img_path))[0].lower()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Individual model predictions\n",
    "            if models['xception_lstm'] is not None:\n",
    "                pred = torch.sigmoid(models['xception_lstm'](image_tensor)).item()\n",
    "                predictions['xception_lstm'].append(pred)\n",
    "            \n",
    "            if models['xception'] is not None:\n",
    "                pred = torch.sigmoid(models['xception'](image_tensor)).item()\n",
    "                predictions['xception'].append(pred)\n",
    "            \n",
    "            # SVM prediction\n",
    "            if (models['svm_model'] is not None and \n",
    "                image_id in models['features_dict']):\n",
    "                features = models['features_dict'][image_id].reshape(1, -1)\n",
    "                pred = models['svm_model'].predict_proba(features)[0][1]\n",
    "                predictions['svm'].append(pred)\n",
    "            else:\n",
    "                predictions['svm'].append(None)\n",
    "        \n",
    "        # Ensemble prediction\n",
    "        try:\n",
    "            result = predict_ensemble(img_path, models, fallback_to_cnn=True)\n",
    "            predictions['ensemble'].append(result['prob_pneumonia'])\n",
    "        except:\n",
    "            predictions['ensemble'].append(0.5)\n",
    "    \n",
    "    # Calculate metrics for each model\n",
    "    results = {}\n",
    "    true_labels = np.array(true_labels)\n",
    "    \n",
    "    for model_name, preds in predictions.items():\n",
    "        valid_preds = [p for p in preds if p is not None]\n",
    "        if len(valid_preds) > 0:\n",
    "            valid_indices = [i for i, p in enumerate(preds) if p is not None]\n",
    "            valid_true = true_labels[valid_indices]\n",
    "            pred_labels = (np.array(valid_preds) > 0.5).astype(int)\n",
    "            \n",
    "            accuracy = np.mean(pred_labels == valid_true)\n",
    "            results[model_name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'samples': len(valid_preds)\n",
    "            }\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    print(\"-\" * 40)\n",
    "    for model_name, metrics in results.items():\n",
    "        print(f\"{model_name.replace('_', ' ').title()::<15} Accuracy: {metrics['accuracy']:.4f} ({metrics['samples']} samples)\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Running the Evaluation\n",
    "\n",
    "Uncomment the cells below to run the ensemble evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Evaluate ensemble on test set\n",
    "# Note: Adjust paths according to your data structure\n",
    "\n",
    "# results = evaluate_ensemble(\n",
    "#     test_dir=\"../data/test\",\n",
    "#     features_file=\"../data/test_features.csv\",\n",
    "#     fallback_to_cnn=True\n",
    "# )\n",
    "\n",
    "print(\"Ensemble evaluation framework is ready.\")\n",
    "print(\"Uncomment the above code to run evaluation when models and data are available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Single image prediction\n",
    "# demo_single_prediction(\"../data/test/pneumonia/sample_image.jpg\")\n",
    "\n",
    "print(\"Single image prediction demo is ready.\")\n",
    "print(\"Uncomment the above code and provide an image path to test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compare individual models vs ensemble\n",
    "# comparison_results = compare_individual_vs_ensemble(\n",
    "#     test_dir=\"../data/test\",\n",
    "#     sample_size=200\n",
    "# )\n",
    "\n",
    "print(\"Model comparison framework is ready.\")\n",
    "print(\"Uncomment the above code to compare individual models vs ensemble.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Insights and Benefits\n",
    "\n",
    "### Ensemble Advantages:\n",
    "\n",
    "1. **Complementary Strengths**: \n",
    "   - CNNs excel at spatial feature detection\n",
    "   - LSTM captures sequential patterns in feature maps\n",
    "   - SVM provides robust statistical classification\n",
    "\n",
    "2. **Improved Robustness**:\n",
    "   - Reduces individual model weaknesses\n",
    "   - Better generalization to unseen data\n",
    "   - More reliable predictions in clinical settings\n",
    "\n",
    "3. **Confidence Estimation**:\n",
    "   - Agreement between models indicates higher confidence\n",
    "   - Disagreement suggests uncertain cases requiring human review\n",
    "\n",
    "4. **Flexibility**:\n",
    "   - Graceful degradation when some models are unavailable\n",
    "   - Adaptable weighting schemes for different scenarios\n",
    "\n",
    "### Implementation Notes:\n",
    "\n",
    "- **Feature Extraction**: SVM requires pre-computed statistical features from ROI analysis\n",
    "- **Model Loading**: Each component model can be trained independently\n",
    "- **Inference Speed**: Trade-off between accuracy and computational cost\n",
    "- **Clinical Integration**: Ensemble provides interpretable confidence scores\n",
    "\n",
    "This ensemble approach demonstrates how multiple AI techniques can be combined to create a more robust and reliable pneumonia detection system suitable for clinical applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}